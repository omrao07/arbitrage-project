{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c25e75d",
   "metadata": {},
   "source": [
    "# ðŸ§ª Experiments Report\n",
    "\n",
    "This report aggregates experiment runs (train/val metrics, hyperparameters, tags) and produces summaries & charts.\n",
    "\n",
    "### How to use\n",
    "1. Drop a `runs.csv` **or** `runs.json` into the same folder as this notebook.\n",
    "   - Expected columns/fields (flexible): `id, timestamp, experiment, tag, lr, batch_size, epochs, val_loss, val_acc, sharpe, drawdown, notes`.\n",
    "2. Run all cells. If no data file is found, the notebook fabricates a small dummy dataset so you can see the visuals.\n",
    "3. Tweak the filters at the top to select subsets (e.g., a specific experiment or tag) and re-run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac80836",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, math, datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 4)\n",
    "DATA_DIR = Path(\".\")\n",
    "CSV_PATH = DATA_DIR / \"runs.csv\"\n",
    "JSON_PATH = DATA_DIR / \"runs.json\"\n",
    "\n",
    "# ---- Filters (edit here) ----\n",
    "FILTER_EXPERIMENT = None      # e.g., \"sentiment_v2\" or None\n",
    "FILTER_TAG = None             # e.g., \"baseline\" or None\n",
    "SORT_BY = \"val_loss\"          # default sort metric\n",
    "TOP_K = 10\n",
    "\n",
    "def _dummy(n=30, seed=7):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    rows = []\n",
    "    base = datetime.datetime.now()\n",
    "    for i in range(n):\n",
    "        ts = base - datetime.timedelta(hours=(n - i))\n",
    "        lr = 10**rng.uniform(-5, -2)\n",
    "        bs = int(rng.choice([16, 32, 64, 128]))\n",
    "        epochs = int(rng.integers(5, 31))\n",
    "        val_loss = float(rng.normal(0.35, 0.05)) + 0.1*(0.0005/lr) + 0.01*(64/bs)\n",
    "        val_acc = float(np.clip(rng.normal(0.80, 0.05), 0.5, 0.99)) - 0.2*(val_loss-0.3)\n",
    "        sharpe = float(np.clip(rng.normal(1.2, 0.4), -0.2, 3.0)) + 0.5*(0.85 - val_loss)\n",
    "        drawdown = float(np.clip(rng.normal(0.10, 0.05), 0.02, 0.35)) + 0.2*(val_loss-0.3)\n",
    "        rows.append({\n",
    "            \"id\": f\"run_{i:03d}\",\n",
    "            \"timestamp\": ts.isoformat(),\n",
    "            \"experiment\": rng.choice([\"sentiment_v2\",\"regime_map\",\"vol_surface\",\"alpha_blend\"]),\n",
    "            \"tag\": rng.choice([\"baseline\",\"tuned\",\"ablation\",\"debug\"]),\n",
    "            \"lr\": lr,\n",
    "            \"batch_size\": bs,\n",
    "            \"epochs\": epochs,\n",
    "            \"val_loss\": max(val_loss, 0.05),\n",
    "            \"val_acc\": float(np.clip(val_acc, 0.5, 0.999)),\n",
    "            \"sharpe\": sharpe,\n",
    "            \"drawdown\": drawdown,\n",
    "            \"notes\": \"auto-dummy\"\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def _load_runs():\n",
    "    if CSV_PATH.exists():\n",
    "        df = pd.read_csv(CSV_PATH)\n",
    "    elif JSON_PATH.exists():\n",
    "        with open(JSON_PATH, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "        df = pd.DataFrame(data)\n",
    "    else:\n",
    "        df = _dummy()\n",
    "    # ensure expected columns exist\n",
    "    for col in [\"id\",\"timestamp\",\"experiment\",\"tag\",\"val_loss\",\"val_acc\",\"sharpe\",\"drawdown\"]:\n",
    "        if col not in df.columns:\n",
    "            df[col] = np.nan\n",
    "    # coerce types\n",
    "    if \"timestamp\" in df.columns:\n",
    "        df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "df = _load_runs()\n",
    "orig_rows = len(df)\n",
    "if FILTER_EXPERIMENT:\n",
    "    df = df[df[\"experiment\"] == FILTER_EXPERIMENT]\n",
    "if FILTER_TAG:\n",
    "    df = df[df[\"tag\"] == FILTER_TAG]\n",
    "df = df.sort_values(by=[SORT_BY], ascending=True if SORT_BY.lower().endswith(\"loss\") else False) # type: ignore\n",
    "print(f\"Loaded {orig_rows} runs; after filters: {len(df)}\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58e75da",
   "metadata": {},
   "source": [
    "## Summary Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c3f273",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = {\n",
    "    \"n_runs\": int(len(df)),\n",
    "    \"best_val_loss\": float(df[\"val_loss\"].min(skipna=True)),\n",
    "    \"best_val_acc\": float(df[\"val_acc\"].max(skipna=True)),\n",
    "    \"best_sharpe\": float(df[\"sharpe\"].max(skipna=True)),\n",
    "    \"min_drawdown\": float(df[\"drawdown\"].min(skipna=True)),\n",
    "}\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedb88cb",
   "metadata": {},
   "source": [
    "## Top-K Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb98a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [c for c in [\"id\",\"timestamp\",\"experiment\",\"tag\",\"val_loss\",\"val_acc\",\"sharpe\",\"drawdown\",\"lr\",\"batch_size\",\"epochs\",\"notes\"] if c in df.columns]\n",
    "topk = df[cols].head(TOP_K).reset_index(drop=True)\n",
    "topk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4421c762",
   "metadata": {},
   "source": [
    "## Charts\n",
    "\n",
    "- **Metric over time** (val_loss, val_acc)\n",
    "- **Hyperparameter sweeps** (lr vs metrics; batch_size vs metrics)\n",
    "- **Pareto frontier** (minimize val_loss, minimize drawdown / maximize sharpe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe08012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _plot_series(x, y, title, xlabel, ylabel):\n",
    "    plt.figure()\n",
    "    plt.plot(x, y, marker='o', linewidth=1)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "if \"timestamp\" in df.columns and df[\"timestamp\"].notna().any():\n",
    "    _plot_series(df[\"timestamp\"], df[\"val_loss\"], \"Validation Loss over Time\", \"Time\", \"val_loss\")\n",
    "    if \"val_acc\" in df.columns:\n",
    "        _plot_series(df[\"timestamp\"], df[\"val_acc\"], \"Validation Accuracy over Time\", \"Time\", \"val_acc\")\n",
    "\n",
    "if \"lr\" in df.columns:\n",
    "    _plot_series(np.log10(df[\"lr\"].astype(float).replace(0,np.nan)), df[\"val_loss\"], \"val_loss vs log10(lr)\", \"log10(lr)\", \"val_loss\")\n",
    "\n",
    "if \"batch_size\" in df.columns:\n",
    "    _plot_series(df[\"batch_size\"], df[\"val_loss\"], \"val_loss vs batch_size\", \"batch_size\", \"val_loss\")\n",
    "\n",
    "# Pareto: minimize val_loss and drawdown, maximize sharpe (we'll use -sharpe to plot a 2D frontier)\n",
    "if set([\"val_loss\",\"drawdown\"]).issubset(df.columns):\n",
    "    x = df[\"val_loss\"].astype(float).values\n",
    "    y = df[\"drawdown\"].astype(float).values\n",
    "    idx = np.argsort(x) # type: ignore\n",
    "    x2, y2 = x[idx], y[idx]\n",
    "    # lower envelope\n",
    "    frontier_x, frontier_y = [], []\n",
    "    cur = float(\"inf\")\n",
    "    for xv, yv in zip(x2, y2):\n",
    "        if yv < cur:\n",
    "            frontier_x.append(xv); frontier_y.append(yv); cur = yv\n",
    "    plt.figure()\n",
    "    plt.scatter(x, y, s=20) # type: ignore\n",
    "    plt.plot(frontier_x, frontier_y, linewidth=2)\n",
    "    plt.title(\"Pareto Frontier: val_loss vs drawdown (lower-left is better)\")\n",
    "    plt.xlabel(\"val_loss\")\n",
    "    plt.ylabel(\"drawdown\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afbc5ae",
   "metadata": {},
   "source": [
    "## Export: Markdown Summary\n",
    "Creates a `EXPERIMENTS_SUMMARY.md` you can paste into PRs or wikis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a46690",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = [\n",
    "    \"# Experiments Summary\\n\",\n",
    "    f\"Generated: {datetime.datetime.now().isoformat()}\\n\\n\",\n",
    "    f\"Total runs: {summary['n_runs']}\\n\\n\",\n",
    "    f\"- Best val_loss: {summary['best_val_loss']:.4f}\\n\",\n",
    "    f\"- Best val_acc:  {summary['best_val_acc']:.4f}\\n\",\n",
    "    f\"- Best sharpe:   {summary['best_sharpe']:.4f}\\n\",\n",
    "    f\"- Min drawdown:  {summary['min_drawdown']:.4f}\\n\\n\",\n",
    "    \"## Top Runs\\n\",\n",
    "]\n",
    "for i, row in topk.iterrows():\n",
    "    rid = row.get(\"id\", f\"#{i}\")\n",
    "    ts = row.get(\"timestamp\", \"-\")\n",
    "    exp = row.get(\"experiment\", \"-\")\n",
    "    tag = row.get(\"tag\", \"-\")\n",
    "    vl = row.get(\"val_loss\", float(\"nan\"))\n",
    "    va = row.get(\"val_acc\", float(\"nan\"))\n",
    "    sh = row.get(\"sharpe\", float(\"nan\"))\n",
    "    dd = row.get(\"drawdown\", float(\"nan\"))\n",
    "    lines.append(f\"- **{rid}** | {ts} | {exp} / {tag} | val_loss={vl:.4f} | val_acc={va:.4f} | sharpe={sh:.2f} | dd={dd:.2f}\\n\")\n",
    "\n",
    "with open(\"EXPERIMENTS_SUMMARY.md\", \"w\") as f:\n",
    "    f.writelines(lines)\n",
    "print(\"Wrote EXPERIMENTS_SUMMARY.md\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
