{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5879a9e9",
   "metadata": {},
   "source": [
    "\n",
    "# ⚡ Latency Simulator — Tail-at-Scale & Trading Impact\n",
    "\n",
    "_Date generated: 2025-09-03_\n",
    "\n",
    "This notebook simulates **end-to-end order latency**, queueing effects, and the **P&L impact** of latency tails.\n",
    "\n",
    "**What you get**\n",
    "- Synthetic latency pipeline (network → gateway → risk → venue ACK)\n",
    "- **Microburst traffic** (Poisson arrivals), lognormal service times\n",
    "- Queueing models: **M/M/1** response vs utilization\n",
    "- SLO tracking (e.g., **p99 < 50 ms**), error-budget burn\n",
    "- Fill/alpha decay model → $$ cost of latency\n",
    "- A/B scenarios: baseline vs **co-location optimization**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076abf18",
   "metadata": {},
   "source": [
    "## 0) Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4ee299",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N_REQUESTS = 50_000\n",
    "\n",
    "# Pipeline components (lognormal ms)\n",
    "NET_MEAN_MS, NET_SIGMA = 2.5, 0.35\n",
    "GW_MEAN_MS, GW_SIGMA   = 1.5, 0.30\n",
    "RISK_MEAN_MS, RISK_SIG = 3.0, 0.40\n",
    "VENUE_MEAN_MS, VENUE_SIG = 5.0, 0.45\n",
    "\n",
    "# Arrival process\n",
    "LAMBDA_RPS = 600   # average requests per second\n",
    "BURST_FACTOR = 3.0 # multiplier during bursts\n",
    "BURST_PROB = 0.08  # prob a given second is a burst second\n",
    "\n",
    "# SLO\n",
    "SLO_PERC = 99.0\n",
    "SLO_THRESH_MS = 50.0\n",
    "\n",
    "# Cost model\n",
    "ALPHA_DECAY_BP_PER_MS = 0.002   # bp of edge lost per extra ms vs competitor\n",
    "COMPETITOR_LAT_MS = 10.0        # fixed competitor latency (for model)\n",
    "NOTIONAL_PER_ORDER = 50_000     # $ notional per order\n",
    "FILL_SENSITIVITY = 0.015        # prob of losing fill per extra ms (soft)\n",
    "\n",
    "SEED = 7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc2bf1e",
   "metadata": {},
   "source": [
    "## 1) Setup & Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba48e1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "def lognormal_ms(mean_ms, sigma):\n",
    "    # Convert desired mean to lognormal parameters\n",
    "    # mean = exp(mu + 0.5*sigma^2) => mu = ln(mean) - 0.5*sigma^2\n",
    "    mu = np.log(mean_ms) - 0.5*(sigma**2)\n",
    "    return np.exp(rng.normal(mu, sigma))\n",
    "\n",
    "def percentile(x, p):\n",
    "    return np.percentile(x, p)\n",
    "\n",
    "def series_percentiles(x: pd.Series, ps=(50,95,99)):\n",
    "    return {f\"p{p}\": np.percentile(x, p) for p in ps}\n",
    "\n",
    "def rolling_percentile(x: pd.Series, p=99, win=500):\n",
    "    return x.rolling(win).apply(lambda s: np.percentile(s, p), raw=True)\n",
    "\n",
    "def mm1_response_time(lambda_rate, mu_rate):\n",
    "    # R = 1/(mu - lambda)\n",
    "    rho = lambda_rate / mu_rate\n",
    "    if rho >= 1.0: \n",
    "        return np.inf, rho\n",
    "    return 1.0/(mu_rate - lambda_rate), rho\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8fb4e2",
   "metadata": {},
   "source": [
    "## 2) Generate Requests with Microbursts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44655b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assign each request to a second; some seconds are bursty\n",
    "n_seconds = int(np.ceil(N_REQUESTS / LAMBDA_RPS)) + 5\n",
    "is_burst = rng.random(n_seconds) < BURST_PROB\n",
    "per_sec_rate = np.where(is_burst, LAMBDA_RPS*BURST_FACTOR, LAMBDA_RPS)\n",
    "\n",
    "# Draw counts each second\n",
    "counts = rng.poisson(per_sec_rate)\n",
    "counts[0] += max(0, N_REQUESTS - counts.sum())  # adjust to hit ~N_REQUESTS\n",
    "counts = np.cumsum(counts)\n",
    "ts = []\n",
    "for s in range(1, len(counts)):\n",
    "    n = counts[s] - counts[s-1]\n",
    "    if n <= 0: continue\n",
    "    # uniform arrivals within the second s\n",
    "    offs = rng.random(n)\n",
    "    ts.extend(list((s + offs)))\n",
    "t = pd.Series(sorted(ts))[:N_REQUESTS]\n",
    "t.index.name = \"request_id\"\n",
    "t.name = \"arrival_sec\"\n",
    "t.head(), len(t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2609ed39",
   "metadata": {},
   "source": [
    "## 3) Draw Component Latencies & Compose E2E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcabbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def draw_pipeline(n, params):\n",
    "    comps = {}\n",
    "    for name,(m,s) in params.items():\n",
    "        comps[name] = np.array([lognormal_ms(m, s) for _ in range(n)])\n",
    "    df = pd.DataFrame(comps)\n",
    "    df[\"latency_ms\"] = df.sum(axis=1)\n",
    "    return df\n",
    "\n",
    "params = {\n",
    "    \"net_ms\": (NET_MEAN_MS, NET_SIGMA),\n",
    "    \"gw_ms\": (GW_MEAN_MS, GW_SIGMA),\n",
    "    \"risk_ms\": (RISK_MEAN_MS, RISK_SIG),\n",
    "    \"venue_ms\": (VENUE_MEAN_MS, VENUE_SIG),\n",
    "}\n",
    "\n",
    "lat = draw_pipeline(N_REQUESTS, params)\n",
    "lat[\"arrival_sec\"] = t.values\n",
    "lat = lat.sort_values(\"arrival_sec\").reset_index(drop=True)\n",
    "lat.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667341f3",
   "metadata": {},
   "source": [
    "## 4) Latency Stats & Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f2c4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "p = series_percentiles(lat[\"latency_ms\"], ps=(50,90,95,99,99.9))\n",
    "p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb936ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10,3.5))\n",
    "lat[\"latency_ms\"].hist(bins=100)\n",
    "plt.title(\"E2E Latency Histogram (ms)\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,3.5))\n",
    "cdf = np.sort(lat[\"latency_ms\"].values) # type: ignore\n",
    "y = np.linspace(0,1,len(cdf))\n",
    "plt.plot(cdf, y)\n",
    "plt.title(\"Latency CDF\")\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e84946",
   "metadata": {},
   "source": [
    "## 5) SLO Tracking & Error-Budget Burn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fce3280",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "win = 1000\n",
    "p99 = rolling_percentile(lat[\"latency_ms\"], p=SLO_PERC, win=win) # type: ignore\n",
    "slo_breach = (p99 > SLO_THRESH_MS).astype(int)\n",
    "\n",
    "plt.figure(figsize=(10,3.5))\n",
    "plt.plot(p99.index, p99.values) # type: ignore\n",
    "plt.axhline(SLO_THRESH_MS, linestyle='--')\n",
    "plt.title(f\"Rolling p{int(SLO_PERC)} (window={win}) vs SLO\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "burn = slo_breach.rolling(2000).mean()\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.plot(burn.index, burn.values) # type: ignore\n",
    "plt.title(\"SLO Breach Rate (rolling)\")\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878f2df1",
   "metadata": {},
   "source": [
    "## 6) M/M/1 Response Time vs Utilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e63d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Approximate service rate (per ms -> per sec). Use mean of gateway stage as bottleneck example.\n",
    "service_ms = lat[\"gw_ms\"].mean()\n",
    "mu_rate = 1000.0 / service_ms   # per second\n",
    "util = np.linspace(0.1, 0.99, 50)\n",
    "resp = []\n",
    "for rho in util:\n",
    "    lam = rho * mu_rate\n",
    "    R, _ = mm1_response_time(lam, mu_rate)\n",
    "    resp.append(R*1000.0) # sec->ms\n",
    "\n",
    "plt.figure(figsize=(10,3.5))\n",
    "plt.plot(util, resp)\n",
    "plt.title(\"M/M/1 Mean Response Time vs Utilization (gateway stage)\")\n",
    "plt.xlabel(\"Utilization ρ\"); plt.ylabel(\"Response Time (ms)\")\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a57b6f",
   "metadata": {},
   "source": [
    "## 7) Cost of Latency — Fill Loss & Alpha Decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb1051c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "delta_ms = np.clip(lat[\"latency_ms\"] - COMPETITOR_LAT_MS, 0, None)\n",
    "# probability of losing the fill due to being slower\n",
    "p_lose = 1 - np.exp(-FILL_SENSITIVITY * delta_ms)\n",
    "# expected alpha lost (bp) conditional on fill\n",
    "alpha_lost_bp = ALPHA_DECAY_BP_PER_MS * delta_ms\n",
    "# expected cost per order in $\n",
    "expected_cost = (p_lose * 0.5 + (1 - p_lose) * (alpha_lost_bp/10000.0)) * NOTIONAL_PER_ORDER\n",
    "lat[\"delta_ms\"] = delta_ms\n",
    "lat[\"p_lose\"] = p_lose\n",
    "lat[\"cost_$\"] = expected_cost\n",
    "\n",
    "lat[[\"latency_ms\",\"delta_ms\",\"p_lose\",\"cost_$\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab533a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10,3.5))\n",
    "plt.scatter(lat[\"latency_ms\"][::200], lat[\"cost_$\"][::200], s=8)\n",
    "plt.title(\"Latency vs Expected Cost per Order ($)\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "total_cost = lat[\"cost_$\"].sum()\n",
    "total_cost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348f9190",
   "metadata": {},
   "source": [
    "## 8) A/B Scenario — Co-Location Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bc2017",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def apply_colo(df: pd.DataFrame, net_factor=0.4, venue_factor=0.8):\n",
    "    df2 = df.copy()\n",
    "    df2[\"net_ms\"] = df2[\"net_ms\"] * net_factor\n",
    "    df2[\"venue_ms\"] = df2[\"venue_ms\"] * venue_factor\n",
    "    df2[\"latency_ms\"] = df2[[\"net_ms\",\"gw_ms\",\"risk_ms\",\"venue_ms\"]].sum(axis=1)\n",
    "    return df2\n",
    "\n",
    "lat_colo = apply_colo(lat, net_factor=0.35, venue_factor=0.75)\n",
    "delta_ms2 = np.clip(lat_colo[\"latency_ms\"] - COMPETITOR_LAT_MS, 0, None)\n",
    "p_lose2 = 1 - np.exp(-FILL_SENSITIVITY * delta_ms2)\n",
    "expected_cost2 = (p_lose2 * 0.5 + (1 - p_lose2) * (ALPHA_DECAY_BP_PER_MS * delta_ms2/10000.0)) * NOTIONAL_PER_ORDER\n",
    "lat_colo[\"cost_$\"] = expected_cost2\n",
    "\n",
    "base_cost = lat[\"cost_$\"].sum()\n",
    "colo_cost = lat_colo[\"cost_$\"].sum()\n",
    "savings = base_cost - colo_cost\n",
    "{\"base_total_cost_$\": float(base_cost), \"colo_total_cost_$\": float(colo_cost), \"savings_$\": float(savings)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22e9287",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compare distributions\n",
    "plt.figure(figsize=(10,3.5))\n",
    "lat[\"latency_ms\"].plot(kind=\"kde\", label=\"Base\")\n",
    "lat_colo[\"latency_ms\"].plot(kind=\"kde\", label=\"Co-lo\")\n",
    "plt.title(\"Latency Density: Base vs Co-lo\")\n",
    "plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,3.5))\n",
    "plt.hist(lat[\"cost_$\"], bins=80, alpha=0.6, label=\"Base\")\n",
    "plt.hist(lat_colo[\"cost_$\"], bins=80, alpha=0.6, label=\"Co-lo\")\n",
    "plt.title(\"Per-Order Expected Cost Distribution\")\n",
    "plt.legend(); plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c40aa0",
   "metadata": {},
   "source": [
    "## 9) Export Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da17b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "summary = pd.DataFrame({\n",
    "    \"metric\": [\"p50_ms\",\"p95_ms\",\"p99_ms\",\"p999_ms\",\"total_cost_$\",\"total_cost_colo_$\",\"savings_$\"],\n",
    "    \"value\": [\n",
    "        np.percentile(lat[\"latency_ms\"],50),\n",
    "        np.percentile(lat[\"latency_ms\"],95),\n",
    "        np.percentile(lat[\"latency_ms\"],99),\n",
    "        np.percentile(lat[\"latency_ms\"],99.9),\n",
    "        base_cost, colo_cost, savings\n",
    "    ]\n",
    "})\n",
    "out_path = \"reports/latency_summary.csv\"\n",
    "import os\n",
    "os.makedirs(\"reports\", exist_ok=True)\n",
    "summary.to_csv(out_path, index=False)\n",
    "out_path\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
