{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89fb507e",
   "metadata": {},
   "source": [
    "\n",
    "# ðŸ“ˆ Weekly Performance Report\n",
    "\n",
    "This notebook generates a **weekly performance pack** with:\n",
    "- Weekly & YTD returns\n",
    "- Cumulative equity curve\n",
    "- PnL attribution by **strategy / sector / asset**\n",
    "- Rolling Sharpe (12w), drawdowns\n",
    "- Top/Worst contributors\n",
    "- Exportable summary tables\n",
    "\n",
    "> It auto-detects data in `data/` and falls back to **synthetic** data if files are missing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971a0848",
   "metadata": {},
   "source": [
    "## 0) Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d13f34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Input files (CSV). Wide formats are supported where appropriate.\n",
    "PATH_RETURNS   = \"data/returns.csv\"      # wide: date, TICK1, TICK2, ... (daily returns in decimal)\n",
    "PATH_PRICES    = \"data/prices.csv\"       # wide: date, TICK1, TICK2, ... (daily prices) as fallback\n",
    "PATH_POSITIONS = \"data/positions.csv\"    # columns: ticker, quantity, avg_price, sector, strategy (optional)\n",
    "PATH_MAP       = \"data/asset_map.csv\"    # optional: ticker -> sector,strategy mapping\n",
    "\n",
    "# Report settings\n",
    "ROLLING_WEEKS_SHARPE = 12\n",
    "TOP_K = 10     # top contributors to show\n",
    "WEEK_FREQ = \"W-FRI\"   # weekly close day\n",
    "\n",
    "# Output\n",
    "OUT_DIR = \"reports\"\n",
    "SUMMARY_CSV = \"weekly_summary.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1de6c5",
   "metadata": {},
   "source": [
    "## 1) Setup & Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca64c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, math\n",
    "from typing import List, Dict, Any, Optional\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.options.display.float_format = \"{:,.4f}\".format\n",
    "\n",
    "def load_wide_csv(path: str) -> Optional[pd.DataFrame]:\n",
    "    if os.path.exists(path):\n",
    "        df = pd.read_csv(path, parse_dates=[\"date\"]).set_index(\"date\").sort_index()\n",
    "        return df\n",
    "    return None\n",
    "\n",
    "def to_weekly(df: pd.DataFrame, method: str = \"sum\", freq: str = \"W-FRI\") -> pd.DataFrame:\n",
    "    # Returns: sum (approx for small daily returns), Prices: last\n",
    "    if method == \"sum\":\n",
    "        return df.resample(freq).sum(min_count=1)\n",
    "    elif method == \"last\":\n",
    "        return df.resample(freq).last()\n",
    "    else:\n",
    "        raise ValueError(\"Unknown method\")\n",
    "\n",
    "def drawdown_curve(nav: pd.Series) -> pd.Series:\n",
    "    rm = nav.cummax()\n",
    "    return nav / rm - 1.0\n",
    "\n",
    "def ann_sharpe(ret: pd.Series, periods_per_year=52) -> float:\n",
    "    mu = ret.mean() * periods_per_year\n",
    "    sd = ret.std(ddof=1) * math.sqrt(periods_per_year)\n",
    "    return float(mu / sd) if sd > 0 else float(\"nan\")\n",
    "\n",
    "def rolling_sharpe(ret_w: pd.Series, window: int, periods_per_year=52) -> pd.Series:\n",
    "    mu = ret_w.rolling(window).mean() * periods_per_year\n",
    "    sd = ret_w.rolling(window).std(ddof=1) * math.sqrt(periods_per_year)\n",
    "    rs = mu / sd\n",
    "    return rs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80463e41",
   "metadata": {},
   "source": [
    "## 2) Load Data (with synthetic fallback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5731d762",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Try returns first (preferred), fallback to prices -> pct_change, else synthesize\n",
    "rets = load_wide_csv(PATH_RETURNS)\n",
    "if rets is None:\n",
    "    prices = load_wide_csv(PATH_PRICES)\n",
    "    if prices is not None:\n",
    "        rets = prices.pct_change().dropna(how=\"all\").fillna(0.0)\n",
    "\n",
    "if rets is None or rets.empty:\n",
    "    # Synthetic: 16 assets, sector/strategy groups\n",
    "    rng = np.random.default_rng(7)\n",
    "    dates = pd.bdate_range(\"2024-01-01\", periods=380)\n",
    "    n = 16\n",
    "    # Sector drifts to create structure\n",
    "    sectors = np.array([\"EQT\",\"EQT\",\"EQT\",\"EQT\",\"BOND\",\"BOND\",\"CMD\",\"CMD\",\"FX\",\"FX\",\"CRY\",\"CRY\",\"ALT\",\"ALT\",\"VOL\",\"VOL\"])\n",
    "    base_mu = {\"EQT\":0.0003,\"BOND\":0.0001,\"CMD\":0.0002,\"FX\":0.0000,\"CRY\":0.0006,\"ALT\":0.0002,\"VOL\":0.0002}\n",
    "    base_sd = {\"EQT\":0.012,\"BOND\":0.004,\"CMD\":0.009,\"FX\":0.006,\"CRY\":0.03,\"ALT\":0.01,\"VOL\":0.015}\n",
    "    data = []\n",
    "    for i in range(n):\n",
    "        sec = sectors[i]\n",
    "        mu = base_mu[sec]; sd = base_sd[sec]\n",
    "        data.append(rng.normal(mu, sd, size=len(dates)))\n",
    "    cols = [f\"T{i:02d}\" for i in range(n)]\n",
    "    rets = pd.DataFrame(np.array(data).T, index=dates, columns=cols)\n",
    "\n",
    "# Positions / mapping\n",
    "pos = load_wide_csv(PATH_POSITIONS)\n",
    "if pos is not None:\n",
    "    # if loaded as wide by mistake, fix\n",
    "    if \"ticker\" not in pos.columns:\n",
    "        pos = None\n",
    "\n",
    "mapping = load_wide_csv(PATH_MAP)\n",
    "if mapping is not None and \"ticker\" not in mapping.columns:\n",
    "    mapping = None\n",
    "\n",
    "# Build a join map: ticker -> sector,strategy\n",
    "map_df = None\n",
    "if mapping is not None:\n",
    "    map_df = mapping[[\"ticker\"] + [c for c in [\"sector\",\"strategy\"] if c in mapping.columns]].set_index(\"ticker\")\n",
    "\n",
    "elif pos is not None:\n",
    "    map_df = pos.set_index(\"ticker\")[[c for c in [\"sector\",\"strategy\"] if c in pos.columns]]\n",
    "\n",
    "else:\n",
    "    # Synthetic map\n",
    "    tickers = rets.columns.tolist()\n",
    "    sectors = [\"EQT\",\"BOND\",\"CMD\",\"FX\",\"CRY\",\"ALT\",\"VOL\"]\n",
    "    strategies = [\"StatArb\",\"MacroRV\",\"Event\",\"Carry\",\"Momentum\"]\n",
    "    rng = np.random.default_rng(11)\n",
    "    sec = rng.choice(sectors, size=len(tickers))\n",
    "    strat = rng.choice(strategies, size=len(tickers))\n",
    "    map_df = pd.DataFrame({\"sector\": sec, \"strategy\": strat}, index=tickers)\n",
    "\n",
    "rets = rets.loc[:, rets.columns.intersection(map_df.index)].copy() # type: ignore\n",
    "map_df = map_df.loc[rets.columns]\n",
    "rets.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be80f0d5",
   "metadata": {},
   "source": [
    "## 3) Weekly Portfolio Returns & Equity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bdbed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Equal-weight portfolio unless weights provided\n",
    "weights = pd.Series(1.0 / rets.shape[1], index=rets.columns) # type: ignore\n",
    "\n",
    "rets_w = to_weekly(rets, method=\"sum\", freq=WEEK_FREQ).fillna(0.0) # type: ignore\n",
    "port_w = (rets_w * weights).sum(axis=1)\n",
    "\n",
    "equity_w = (1 + port_w).cumprod()\n",
    "dd_w = drawdown_curve(equity_w)\n",
    "\n",
    "summary = {\n",
    "    \"Weeks\": int(port_w.shape[0]),\n",
    "    \"YTD Return\": float((1 + port_w[port_w.index.year == port_w.index[-1].year]).prod() - 1.0), # type: ignore\n",
    "    \"Ann. Sharpe (weekly)\": ann_sharpe(port_w),\n",
    "    \"Max Drawdown\": float(dd_w.min())\n",
    "}\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5996e3a",
   "metadata": {},
   "source": [
    "## 4) Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9932491b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10,3.5))\n",
    "port_w.plot(kind=\"bar\")\n",
    "plt.title(\"Weekly Returns\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,3.5))\n",
    "equity_w.plot()\n",
    "plt.title(\"Cumulative Equity (Weekly)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,3.5))\n",
    "rolling_sharpe(port_w, ROLLING_WEEKS_SHARPE).plot()\n",
    "plt.title(f\"Rolling Sharpe ({ROLLING_WEEKS_SHARPE}w)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ee4016",
   "metadata": {},
   "source": [
    "## 5) PnL Attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff717442",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Approx weekly contribution = weight * weekly return (since equal weights)\n",
    "contrib_w = rets_w.mul(weights, axis=1)\n",
    "\n",
    "# By strategy\n",
    "if \"strategy\" in map_df.columns: # type: ignore\n",
    "    strat_map = map_df[\"strategy\"] # type: ignore\n",
    "    by_strat = contrib_w.groupby(by=strat_map, axis=1).sum() # type: ignore\n",
    "else:\n",
    "    by_strat = pd.DataFrame()\n",
    "\n",
    "# By sector\n",
    "if \"sector\" in map_df.columns: # type: ignore\n",
    "    sect_map = map_df[\"sector\"] # type: ignore\n",
    "    by_sect = contrib_w.groupby(by=sect_map, axis=1).sum() # type: ignore\n",
    "else:\n",
    "    by_sect = pd.DataFrame()\n",
    "\n",
    "# Totals (YTD)\n",
    "ytd_mask = by_strat.index.year == by_strat.index[-1].year if not by_strat.empty else None # type: ignore\n",
    "strat_ytd = by_strat[ytd_mask].sum().sort_values(ascending=False) if not by_strat.empty else pd.Series(dtype=float)\n",
    "sect_ytd  = by_sect[ytd_mask].sum().sort_values(ascending=False) if not by_sect.empty else pd.Series(dtype=float)\n",
    "\n",
    "display(strat_ytd.to_frame(\"YTD Contribution\"))\n",
    "display(sect_ytd.to_frame(\"YTD Contribution\"))\n",
    "\n",
    "# Top/Worst assets YTD\n",
    "asset_ytd = contrib_w[ytd_mask].sum().sort_values(ascending=False)\n",
    "top_assets = asset_ytd.head(TOP_K)\n",
    "worst_assets = asset_ytd.tail(TOP_K)\n",
    "\n",
    "display(top_assets.to_frame(\"Top Assets YTD\"))\n",
    "display(worst_assets.to_frame(\"Worst Assets YTD\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da87b5e",
   "metadata": {},
   "source": [
    "### Stacked Weekly Contribution â€” Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a366e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not by_strat.empty:\n",
    "    plt.figure(figsize=(10,3.8))\n",
    "    by_strat.plot(kind=\"bar\", stacked=True, ax=plt.gca())\n",
    "    plt.title(\"Weekly Contribution by Strategy (stacked)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f874a9",
   "metadata": {},
   "source": [
    "### Stacked Weekly Contribution â€” Sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada473f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not by_sect.empty:\n",
    "    plt.figure(figsize=(10,3.8))\n",
    "    by_sect.plot(kind=\"bar\", stacked=True, ax=plt.gca())\n",
    "    plt.title(\"Weekly Contribution by Sector (stacked)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08840b3b",
   "metadata": {},
   "source": [
    "## 6) Weekly Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da6eb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "weekly_tbl = pd.DataFrame({\n",
    "    \"weekly_return\": port_w,\n",
    "    \"equity\": equity_w,\n",
    "    \"drawdown\": dd_w,\n",
    "    \"rolling_sharpe\": rolling_sharpe(port_w, ROLLING_WEEKS_SHARPE)\n",
    "})\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "out_csv = os.path.join(OUT_DIR, SUMMARY_CSV)\n",
    "weekly_tbl.to_csv(out_csv, index=True)\n",
    "print(\"Wrote summary:\", out_csv)\n",
    "\n",
    "weekly_tbl.tail(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4bb808",
   "metadata": {},
   "source": [
    "## 7) Snapshot Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fadfd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "snap = {\n",
    "    \"as_of\": str(weekly_tbl.index[-1].date()) if not weekly_tbl.empty else None,\n",
    "    \"weeks_in_sample\": int(len(weekly_tbl)),\n",
    "    \"ytd_return\": summary[\"YTD Return\"],\n",
    "    \"ann_sharpe_weekly\": summary[\"Ann. Sharpe (weekly)\"],\n",
    "    \"max_drawdown\": summary[\"Max Drawdown\"],\n",
    "    \"top_assets_ytd\": top_assets.to_dict() if 'top_assets' in locals() else {},\n",
    "    \"worst_assets_ytd\": worst_assets.to_dict() if 'worst_assets' in locals() else {},\n",
    "    \"by_strategy_ytd\": strat_ytd.to_dict() if 'strat_ytd' in locals() else {},\n",
    "    \"by_sector_ytd\": sect_ytd.to_dict() if 'sect_ytd' in locals() else {},\n",
    "}\n",
    "snap\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
