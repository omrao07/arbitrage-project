{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abc61493",
   "metadata": {},
   "source": [
    "\n",
    "# ðŸ›¡ï¸ Risk Dashboard\n",
    "\n",
    "A practical dashboard to monitor **portfolio risk**:\n",
    "- Positions & exposures (asset/sector/currency)\n",
    "- P/L and drawdown\n",
    "- Historical **VaR / ES** (non-parametric)\n",
    "- Factor betas (if factor returns available)\n",
    "- Stress tests & scenario analysis\n",
    "- Rolling volatility & correlations\n",
    "\n",
    "> Drop files into `data/` and the notebook will auto-detect them.  \n",
    "> If files are missing, it **simulates** reasonable data so the dashboard always runs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ab9a3f",
   "metadata": {},
   "source": [
    "## 0) Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d433e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data files (CSV)\n",
    "PATH_POSITIONS = \"data/positions.csv\"          # columns: ticker, quantity, avg_price, [sector], [ccy]\n",
    "PATH_PRICES    = \"data/prices.csv\"             # wide: date, TICK1, TICK2, ...\n",
    "PATH_FACTORS   = \"data/factors.csv\"            # wide: date, MKT, SMB, HML, MOM, ... (optional)\n",
    "BASE_CCY       = \"USD\"\n",
    "\n",
    "# Dashboard knobs\n",
    "ALPHA = 0.95            # VaR/ES confidence (one-sided)\n",
    "WINDOW_VOL = 60         # rolling days for volatility\n",
    "WINDOW_CORR = 60        # rolling days for corr heatmap\n",
    "SCENARIOS = {\n",
    "    \"Shock -5% All\": {\"type\": \"uniform_ret\", \"ret\": -0.05},\n",
    "    \"Rates Up 100bp\": {\"type\": \"linear_factor\", \"beta_key\": \"DUR\", \"shock\": -0.06},\n",
    "    \"Flight to Quality\": {\"type\": \"two_bucket\", \"winners\": [\"BOND\"], \"losers\": [\"EQT\"], \"ret_win\": 0.01, \"ret_lose\": -0.03},\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936581cf",
   "metadata": {},
   "source": [
    "## 1) Setup & Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce8c1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, sys, math, json, itertools\n",
    "from typing import Dict, List, Any, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.options.display.float_format = \"{:,.4f}\".format\n",
    "\n",
    "def ensure_cols(df: pd.DataFrame, cols: List[str]) -> pd.DataFrame:\n",
    "    for c in cols:\n",
    "        if c not in df.columns:\n",
    "            df[c] = np.nan\n",
    "    return df\n",
    "\n",
    "def pct_change_safe(x: pd.Series) -> pd.Series:\n",
    "    return x.pct_change().replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "def drawdown_curve(nav: pd.Series) -> pd.Series:\n",
    "    roll_max = nav.cummax()\n",
    "    return nav/roll_max - 1.0\n",
    "\n",
    "def historical_var_es(returns: pd.Series, alpha: float=0.95) -> Dict[str, float]:\n",
    "    r = returns.dropna().sort_values()\n",
    "    if len(r) == 0:\n",
    "        return {\"var\": np.nan, \"es\": np.nan}\n",
    "    idx = int((1-alpha) * len(r))\n",
    "    idx = max(0, min(idx, len(r)-1))\n",
    "    var = -r.iloc[idx]\n",
    "    es = -r.iloc[:idx+1].mean() if idx >= 0 else np.nan\n",
    "    return {\"var\": float(var), \"es\": float(es)}\n",
    "\n",
    "def annualize_vol(ret: pd.Series, freq: int=252) -> float:\n",
    "    return float(ret.std() * math.sqrt(freq))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d8b63b",
   "metadata": {},
   "source": [
    "## 2) Load Data (with synthetic fallback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d656c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_positions(path=PATH_POSITIONS) -> pd.DataFrame:\n",
    "    if os.path.exists(path):\n",
    "        df = pd.read_csv(path)\n",
    "        df = ensure_cols(df, [\"ticker\", \"quantity\", \"avg_price\", \"sector\", \"ccy\"])\n",
    "        df[\"ticker\"] = df[\"ticker\"].astype(str)\n",
    "        df[\"quantity\"] = df[\"quantity\"].astype(float)\n",
    "        df[\"avg_price\"] = df[\"avg_price\"].astype(float)\n",
    "        df[\"sector\"] = df[\"sector\"].fillna(\"Unknown\")\n",
    "        df[\"ccy\"] = df[\"ccy\"].fillna(BASE_CCY)\n",
    "        return df\n",
    "    # Synthetic positions\n",
    "    rng = np.random.default_rng(0)\n",
    "    tickers = [f\"T{i:02d}\" for i in range(12)]\n",
    "    qty = rng.integers(100, 2000, size=len(tickers)).astype(float)\n",
    "    avg_px = rng.uniform(10, 200, size=len(tickers))\n",
    "    sector = rng.choice([\"EQT\",\"BOND\",\"FX\",\"CMD\"], size=len(tickers))\n",
    "    ccy = rng.choice([\"USD\",\"EUR\",\"JPY\"], size=len(tickers), p=[0.7,0.2,0.1])\n",
    "    return pd.DataFrame({\"ticker\": tickers, \"quantity\": qty, \"avg_price\": avg_px, \"sector\": sector, \"ccy\": ccy})\n",
    "\n",
    "def load_prices(path=PATH_PRICES, n_days=500, cols: Optional[List[str]]=None) -> pd.DataFrame:\n",
    "    if os.path.exists(path):\n",
    "        df = pd.read_csv(path, parse_dates=[\"date\"]).set_index(\"date\").sort_index()\n",
    "        return df\n",
    "    # Synthetic prices following sector-ish correlations\n",
    "    rng = np.random.default_rng(1)\n",
    "    if cols is None:\n",
    "        cols = [f\"T{i:02d}\" for i in range(12)]\n",
    "    dates = pd.bdate_range(\"2023-01-01\", periods=n_days)\n",
    "    market = rng.normal(0.0003, 0.01, size=n_days)\n",
    "    prices = {}\n",
    "    for j, c in enumerate(cols):\n",
    "        sector_idx = j % 4\n",
    "        sector = rng.normal(0.0002*(sector_idx+1), 0.008, size=n_days)\n",
    "        idio = rng.normal(0, 0.01, size=n_days)\n",
    "        ret = market + 0.6*sector + 0.4*idio\n",
    "        px = 100 * (1 + pd.Series(ret, index=dates)).cumprod().values # type: ignore\n",
    "        prices[c] = px\n",
    "    return pd.DataFrame(prices, index=dates)\n",
    "\n",
    "def load_factors(path=PATH_FACTORS, n_days=500) -> pd.DataFrame:\n",
    "    if os.path.exists(path):\n",
    "        return pd.read_csv(path, parse_dates=[\"date\"]).set_index(\"date\").sort_index()\n",
    "    # Synthetic factor returns (MKT, SMB, HML, MOM, DUR)\n",
    "    rng = np.random.default_rng(2)\n",
    "    dates = pd.bdate_range(\"2023-01-01\", periods=n_days)\n",
    "    data = {\n",
    "        \"MKT\": rng.normal(0.0004, 0.01, size=len(dates)),\n",
    "        \"SMB\": rng.normal(0.0001, 0.006, size=len(dates)),\n",
    "        \"HML\": rng.normal(0.0001, 0.006, size=len(dates)),\n",
    "        \"MOM\": rng.normal(0.0002, 0.009, size=len(dates)),\n",
    "        \"DUR\": rng.normal(0.0000, 0.004, size=len(dates)),  # duration proxy for rates shock\n",
    "    }\n",
    "    return pd.DataFrame(data, index=dates)\n",
    "\n",
    "pos = load_positions()\n",
    "prices = load_prices(cols=pos[\"ticker\"].tolist())\n",
    "factors = load_factors(n_days=len(prices))\n",
    "\n",
    "prices.head(), pos.head(), factors.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f371b040",
   "metadata": {},
   "source": [
    "## 3) Derived Series: Returns, NAV, PnL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503d9352",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "returns = prices.pct_change().replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "\n",
    "# Mark-to-market current prices (last row)\n",
    "last_px = prices.iloc[-1]\n",
    "mkt_value = (last_px.reindex(pos[\"ticker\"]) * pos[\"quantity\"].values)\n",
    "pos[\"market_value\"] = mkt_value.values\n",
    "pos[\"exposure_%\"] = pos[\"market_value\"] / pos[\"market_value\"].sum()\n",
    "\n",
    "# Portfolio NAV (start at 1.0)\n",
    "weights = pos.set_index(\"ticker\")[\"exposure_%\"].reindex(prices.columns).fillna(0.0)\n",
    "port_ret = (returns * weights).sum(axis=1)\n",
    "nav = (1 + port_ret).cumprod()\n",
    "dd = drawdown_curve(nav)\n",
    "\n",
    "# Daily PnL in currency terms (assume base USD; prices as USD)\n",
    "notional = pos[\"market_value\"].sum()\n",
    "pnl = port_ret * notional\n",
    "\n",
    "pos.sort_values(\"market_value\", ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38ef3ef",
   "metadata": {},
   "source": [
    "## 4) Exposures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05806e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "expo_sector = pos.groupby(\"sector\")[\"market_value\"].sum().sort_values(ascending=False)\n",
    "expo_ccy    = pos.groupby(\"ccy\")[\"market_value\"].sum().sort_values(ascending=False)\n",
    "\n",
    "print(\"Sector exposures:\")\n",
    "display(expo_sector.to_frame(\"mv\"))\n",
    "\n",
    "print(\"Currency exposures:\")\n",
    "display(expo_ccy.to_frame(\"mv\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20c1cd5",
   "metadata": {},
   "source": [
    "## 5) NAV, Drawdown, PnL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8742aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "nav.plot()\n",
    "plt.title(\"Portfolio NAV\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,3))\n",
    "dd.plot()\n",
    "plt.title(\"Drawdown\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,3))\n",
    "pnl.plot()\n",
    "plt.title(\"Daily PnL\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b26001",
   "metadata": {},
   "source": [
    "## 6) Historical VaR / ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ba373e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "risk = historical_var_es(port_ret, alpha=ALPHA)\n",
    "print(f\"{int(ALPHA*100)}% 1-day VaR: {risk['var']:.4%}\")\n",
    "print(f\"{int(ALPHA*100)}% 1-day ES : {risk['es']:.4%}\")\n",
    "print(f\"Ann. Vol (port): {annualize_vol(port_ret):.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8362c4c7",
   "metadata": {},
   "source": [
    "## 7) Rolling Volatility & Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4efa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "roll_vol = returns.rolling(WINDOW_VOL).std().iloc[-1] * np.sqrt(252)\n",
    "\n",
    "plt.figure(figsize=(10,3))\n",
    "roll_vol.sort_values(ascending=False).plot(kind=\"bar\")\n",
    "plt.title(f\"Rolling {WINDOW_VOL}d Volatility (annualized)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlation heatmap of top-N notional names\n",
    "top_ticks = pos.sort_values(\"market_value\", ascending=False)[\"ticker\"].head(12).tolist()\n",
    "corr = returns[top_ticks].tail(WINDOW_CORR).corr()\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.imshow(corr.values, vmin=-1, vmax=1)\n",
    "plt.xticks(range(len(top_ticks)), top_ticks, rotation=45, ha='right')\n",
    "plt.yticks(range(len(top_ticks)), top_ticks)\n",
    "plt.colorbar()\n",
    "plt.title(f\"Correlation (last {WINDOW_CORR}d) â€” Top Exposures\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e981dad",
   "metadata": {},
   "source": [
    "## 8) Factor Betas (OLS, quick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e96806",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def regress_beta(y: pd.Series, X: pd.DataFrame) -> pd.Series:\n",
    "    yv = y.values.reshape(-1,1) # type: ignore\n",
    "    Xv = np.column_stack([np.ones(len(X))] + [X[c].values for c in X.columns]) # type: ignore\n",
    "    beta = np.linalg.lstsq(Xv, yv, rcond=None)[0].flatten()\n",
    "    return pd.Series(beta[1:], index=X.columns)  # exclude intercept\n",
    "\n",
    "# Portfolio factor exposure approximated by weighted asset returns\n",
    "Y = (returns[top_ticks] * weights.reindex(top_ticks)).sum(axis=1).dropna().align(factors, join=\"inner\")[0]\n",
    "X = factors.loc[Y.index]\n",
    "betas = regress_beta(Y, X)\n",
    "\n",
    "display(betas.to_frame(\"beta\"))\n",
    "\n",
    "plt.figure(figsize=(8,3))\n",
    "betas.sort_values(ascending=False).plot(kind=\"bar\")\n",
    "plt.title(\"Estimated Factor Betas (portfolio)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729b720d",
   "metadata": {},
   "source": [
    "## 9) Stress Tests & Scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402f5c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_scenarios(pos: pd.DataFrame, last_prices: pd.Series, scenarios: Dict[str, Dict[str, Any]]) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    mv = (last_prices.reindex(pos['ticker']) * pos['quantity'].values)\n",
    "    for name, sc in scenarios.items():\n",
    "        if sc[\"type\"] == \"uniform_ret\":\n",
    "            ret = sc[\"ret\"]\n",
    "            pnl = (mv * ret).sum()\n",
    "        elif sc[\"type\"] == \"linear_factor\":\n",
    "            # Requires betas; map a beta key to a shock return\n",
    "            shock = sc.get(\"shock\", -0.05)\n",
    "            # Map each ticker to beta via sector proxy (simplified)\n",
    "            # EQT -> behaves like MKT beta 1.0, BOND -> DUR beta 1.0, FX/CMD -> 0.3\n",
    "            map_beta = pos[\"sector\"].map({\"EQT\": 1.0, \"BOND\": 1.0, \"FX\": 0.3, \"CMD\": 0.3}).fillna(0.5)\n",
    "            pnl = float((mv * map_beta.values * shock).sum())\n",
    "        elif sc[\"type\"] == \"two_bucket\":\n",
    "            winners = pos[\"sector\"].isin(sc.get(\"winners\", []))\n",
    "            losers  = pos[\"sector\"].isin(sc.get(\"losers\", []))\n",
    "            ret = np.where(winners, sc.get(\"ret_win\", 0.01), np.where(losers, sc.get(\"ret_lose\", -0.03), 0.0))\n",
    "            pnl = float((mv * ret).sum())\n",
    "        else:\n",
    "            pnl = np.nan\n",
    "        rows.append({\"scenario\": name, \"pnl\": pnl})\n",
    "    return pd.DataFrame(rows).set_index(\"scenario\")\n",
    "\n",
    "sc_df = run_scenarios(pos, last_px, SCENARIOS)\n",
    "display(sc_df)\n",
    "\n",
    "plt.figure(figsize=(8,3))\n",
    "sc_df[\"pnl\"].plot(kind=\"bar\")\n",
    "plt.title(\"Scenario PnL\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547210a5",
   "metadata": {},
   "source": [
    "## 10) Limits & SLO Hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc12b3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "LIMITS = {\n",
    "    \"Max Leverage\": 4.0,\n",
    "    \"Max Gross notional (USD)\": 5_000_000.0,\n",
    "    \"Max DD\": -0.10,\n",
    "    \"Target Vol (ann)\": 0.08,\n",
    "}\n",
    "\n",
    "violations = []\n",
    "gross = pos[\"market_value\"].sum()\n",
    "if dd.min() < LIMITS[\"Max DD\"]:\n",
    "    violations.append((\"Drawdown\", float(dd.min()), LIMITS[\"Max DD\"]))\n",
    "if annualize_vol(port_ret) > LIMITS[\"Target Vol (ann)\"]:\n",
    "    violations.append((\"Volatility\", float(annualize_vol(port_ret)), LIMITS[\"Target Vol (ann)\"]))\n",
    "\n",
    "print(\"Limits:\")\n",
    "print(LIMITS)\n",
    "print(\"\\nPotential Violations:\")\n",
    "for v in violations:\n",
    "    print(\"-\", v[0], \"=\", v[1], \"limit\", v[2])\n",
    "\n",
    "# Placeholder SLO metrics you can export for Prometheus\n",
    "SLO = {\n",
    "    \"risk_var_1d\": risk[\"var\"],\n",
    "    \"risk_es_1d\": risk[\"es\"],\n",
    "    \"nav\": float(nav.iloc[-1]),\n",
    "    \"drawdown\": float(dd.iloc[-1]),\n",
    "}\n",
    "SLO\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
