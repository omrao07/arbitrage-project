{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“Š Factors IC Analysis\n",
    "\n",
    "This notebook computes **Information Coefficient (IC)** for alpha factors in your research pipeline.\n",
    "\n",
    "**IC** = Spearman correlation between factor scores and *next-period* returns.\n",
    "\n",
    "It supports:\n",
    "- Daily IC per factor\n",
    "- Rolling mean IC and ICIR\n",
    "- IC **decay** (multi-horizon)\n",
    "- **Quintile portfolios** and Q5â€“Q1 longâ€“short backtest\n",
    "- IC **heatmap** across time and factors\n",
    "\n",
    "If data files are missing, it auto-generates demo data so you can run the notebook immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10,4)\n",
    "\n",
    "# ---- Config: set your paths or leave defaults ----\n",
    "FACTORS_CSV = './data/factors.csv'   # expected index: date,symbol ; columns: factor names\n",
    "RETURNS_CSV = './data/returns.csv'   # expected index: date,symbol ; column: 'fwd_ret' (or daily returns to be shifted)\n",
    "RETURNS_COL = 'fwd_ret'              # if not found, we'll derive from 'ret' or 'price'\n",
    "MAX_LAG = 10                         # horizons for IC decay\n",
    "N_BUCKETS = 5                        # for quantile portfolios\n",
    "ROLL_WIN = 60                        # rolling IC mean window (days)\n",
    "\n",
    "def _demo():\n",
    "    np.random.seed(42)\n",
    "    dates = pd.date_range('2024-01-01', periods=180, freq='B')\n",
    "    symbols = [f'STK{i:03d}' for i in range(80)]\n",
    "    idx = pd.MultiIndex.from_product([dates, symbols], names=['date','symbol'])\n",
    "    dfF = pd.DataFrame(index=idx)\n",
    "    # latent true driver\n",
    "    latent = np.random.normal(0,1,len(idx))\n",
    "    dfF['momentum'] = latent + np.random.normal(0,1,len(idx))\n",
    "    dfF['value']    = np.random.normal(0,1,len(idx))\n",
    "    dfF['sentiment']= 0.5*latent + np.random.normal(0,1,len(idx))\n",
    "    # forward returns with momentum linkage\n",
    "    dfR = pd.DataFrame(index=idx)\n",
    "    dfR['fwd_ret'] = 0.04*dfF['momentum'] + np.random.normal(0,1,len(idx))\n",
    "    # scale to daily return-like numbers\n",
    "    dfR['fwd_ret'] = dfR['fwd_ret']*0.01\n",
    "    return dfF, dfR\n",
    "\n",
    "def load_factors_returns():\n",
    "    hasF = os.path.exists(FACTORS_CSV)\n",
    "    hasR = os.path.exists(RETURNS_CSV)\n",
    "    if hasF:\n",
    "        dfF = pd.read_csv(FACTORS_CSV)\n",
    "        if {'date','symbol'}.issubset(dfF.columns):\n",
    "            dfF['date'] = pd.to_datetime(dfF['date'])\n",
    "            dfF = dfF.set_index(['date','symbol']).sort_index()\n",
    "        else:\n",
    "            raise ValueError('factors.csv must have columns: date, symbol, <factors...>')\n",
    "    if hasR:\n",
    "        dfR = pd.read_csv(RETURNS_CSV)\n",
    "        if {'date','symbol'}.issubset(dfR.columns):\n",
    "            dfR['date'] = pd.to_datetime(dfR['date'])\n",
    "            dfR = dfR.set_index(['date','symbol']).sort_index()\n",
    "            if RETURNS_COL not in dfR.columns:\n",
    "                # derive fwd returns heuristically\n",
    "                if 'ret' in dfR.columns:\n",
    "                    dfR[RETURNS_COL] = dfR['ret'].groupby(level='symbol').shift(-1)\n",
    "                elif 'price' in dfR.columns:\n",
    "                    pr = dfR['price'].unstack('symbol').sort_index()\n",
    "                    rets = pr.pct_change().stack().rename('ret') # type: ignore\n",
    "                    dfR = dfR.join(rets, how='left')\n",
    "                    dfR[RETURNS_COL] = dfR['ret'].groupby(level='symbol').shift(-1)\n",
    "                else:\n",
    "                    raise ValueError('RETURNS_CSV missing fwd_ret/ret/price columns')\n",
    "        else:\n",
    "            raise ValueError('returns.csv must have columns: date, symbol, <fwd_ret or ret/price>')\n",
    "    if not (hasF and hasR):\n",
    "        return _demo()\n",
    "    return dfF, dfR[[RETURNS_COL]]\n",
    "\n",
    "dfF, dfR = load_factors_returns()\n",
    "factors = [c for c in dfF.columns if c not in ('date','symbol')]\n",
    "print('Loaded factors:', factors[:6], '... (total', len(factors), ')')\n",
    "print('Obs:', len(dfF))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily IC per Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_ic(dfF, dfR, factor):\n",
    "    ics = []\n",
    "    for d, X in dfF[[factor]].groupby(level='date'):\n",
    "        Y = dfR.loc[dfR.index.get_level_values('date')==d]\n",
    "        G = X.join(Y, how='inner')\n",
    "        x = G[factor].values\n",
    "        y = G.iloc[:, -1].values  # last column = fwd_ret\n",
    "        if len(x) > 3 and np.nanstd(x)>0 and np.nanstd(y)>0:\n",
    "            mask = ~np.isnan(x) & ~np.isnan(y)\n",
    "            if mask.sum()>3:\n",
    "                ic,_ = spearmanr(x[mask], y[mask])\n",
    "                ics.append((d, ic))\n",
    "    return pd.Series(dict(ics)).sort_index()\n",
    "\n",
    "ICs = {}\n",
    "for f in factors:\n",
    "    ICs[f] = daily_ic(dfF, dfR, f)\n",
    "ICdf = pd.DataFrame(ICs)\n",
    "ICdf.plot(title='Daily IC by Factor'); plt.axhline(0, linestyle='--'); plt.show()\n",
    "ICdf.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IC Summary (mean, std, ICIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic_mean = ICdf.mean()\n",
    "ic_std  = ICdf.std()\n",
    "ic_ir   = ic_mean / (ic_std + 1e-12)\n",
    "summary = pd.DataFrame({'mean_ic': ic_mean, 'ic_std': ic_std, 'ic_ir': ic_ir}).sort_values('ic_ir', ascending=False)\n",
    "summary.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling Mean IC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll = ICdf.rolling(ROLL_WIN, min_periods=max(5, ROLL_WIN//5)).mean()\n",
    "roll.plot(title=f'Rolling Mean IC (window={ROLL_WIN})'); plt.axhline(0, linestyle='--'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IC Decay (1..MAX_LAG days ahead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ic_decay(dfF, dfR, factor, max_lag=5):\n",
    "    out = {}\n",
    "    for L in range(1, max_lag+1):\n",
    "        # shift returns back by L (so factor at t is compared to return t+L)\n",
    "        dfLag = dfR.copy()\n",
    "        dfLag.iloc[:,0] = dfLag.iloc[:,0].groupby(level='symbol').shift(-(L-1))\n",
    "        s = daily_ic(dfF, dfLag, factor)\n",
    "        out[L] = s.mean()\n",
    "    return out\n",
    "\n",
    "decay_tbl = pd.DataFrame({f: ic_decay(dfF, dfR, f, MAX_LAG) for f in factors}).T\n",
    "decay_tbl.columns = [f'lag_{i}' for i in range(1, MAX_LAG+1)]\n",
    "decay_tbl.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quintile Portfolios & Q5â€“Q1 Longâ€“Short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quintile_portfolio(dfF, dfR, factor, n_buckets=5):\n",
    "    # For each date, sort by factor and split into buckets, compute next return by bucket\n",
    "    buckets = {i: [] for i in range(1, n_buckets+1)}\n",
    "    for d, X in dfF[[factor]].groupby(level='date'):\n",
    "        Y = dfR.loc[dfR.index.get_level_values('date')==d]\n",
    "        G = X.join(Y, how='inner').dropna()\n",
    "        if len(G) < n_buckets:\n",
    "            continue\n",
    "        G = G.sort_values(factor)\n",
    "        splits = np.array_split(G, n_buckets)\n",
    "        for i, part in enumerate(splits, start=1):\n",
    "            buckets[i].append(part.iloc[:,-1].mean())  # type: ignore # mean fwd_ret of bucket\n",
    "    # series per bucket\n",
    "    ser = {f'Q{i}': pd.Series(v).cumsum() for i, v in buckets.items() if len(v)>0}\n",
    "    return ser\n",
    "\n",
    "factor_ = factors[0] if len(factors)>0 else None\n",
    "if factor_:\n",
    "    ser = quintile_portfolio(dfF, dfR, factor_, N_BUCKETS)\n",
    "    if ser:\n",
    "        dfq = pd.DataFrame(ser)\n",
    "        dfq.plot(title=f'Quintile Cum. Returns (factor={factor_})'); plt.show()\n",
    "        if 'Q1' in dfq.columns and f'Q{N_BUCKETS}' in dfq.columns:\n",
    "            ls = dfq[f'Q{N_BUCKETS}'] - dfq['Q1']\n",
    "            plt.figure(); plt.plot(ls.index, ls.values); plt.title('Longâ€“Short (Q5 - Q1) Cum. Return'); plt.show() # type: ignore\n",
    "    else:\n",
    "        print('Insufficient data for quintiles.')\n",
    "else:\n",
    "    print('No factors found.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IC Heatmap (time x factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(ICdf.columns)>0:\n",
    "    plt.figure(figsize=(min(12, 1+len(ICdf.columns)*0.8), 5))\n",
    "    M = ICdf.fillna(0.0).values.T\n",
    "    plt.imshow(M, aspect='auto', interpolation='nearest')\n",
    "    plt.colorbar(label='IC')\n",
    "    plt.yticks(range(len(ICdf.columns)), ICdf.columns) # type: ignore\n",
    "    plt.title('IC Heatmap (factors x time)')\n",
    "    plt.xlabel('time index')\n",
    "    plt.tight_layout(); plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
